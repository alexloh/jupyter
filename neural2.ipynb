{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b27b6a5-0e56-4237-aae5-c695b344f05d",
   "metadata": {},
   "source": [
    "2nd attempt at making my own simple neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ea9b75a-7b10-4dad-92a9-a9e8a6ba9072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-0.298 ]\n",
      " [-0.1476]]\n",
      "Bias2: [0.]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #1\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 3.391832054779133\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[2.1767]\n",
      " [2.0709]\n",
      " [2.0714]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[0.102 ]\n",
      " [0.2524]]\n",
      "Bias2: [2.]\n",
      "d_weights2 = f[[-3.3283]\n",
      " [-3.4758]]\n",
      "  2*(self.y - self.output) = f[[-4.3534]\n",
      " [-2.1418]\n",
      " [-4.1428]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-4.3534]\n",
      " [-2.1418]\n",
      " [-4.1428]]\n",
      "d_bias2 = f[-10.638]\n",
      "  2*(self.y - self.output) = f[[-4.3534]\n",
      " [-2.1418]\n",
      " [-4.1428]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-4.3534]\n",
      " [-2.1418]\n",
      " [-4.1428]]\n",
      "\n",
      "Testing epoch #2\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.2263]\n",
      " [-3.2233]]\n",
      "Bias2: [-8.638]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #3\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.8263]\n",
      " [-2.8233]]\n",
      "Bias2: [-6.638]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #4\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.4263]\n",
      " [-2.4233]]\n",
      "Bias2: [-4.638]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #5\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.0263]\n",
      " [-2.0233]]\n",
      "Bias2: [-2.638]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #6\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.6263]\n",
      " [-1.6233]]\n",
      "Bias2: [-0.638]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #7\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.17524982659271912\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.5057]\n",
      " [0.8721]\n",
      " [0.5036]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.2263]\n",
      " [-1.2233]]\n",
      "Bias2: [1.362]\n",
      "d_weights2 = f[[-0.6539]\n",
      " [-0.6569]]\n",
      "  2*(self.y - self.output) = f[[-1.0115]\n",
      " [ 0.2558]\n",
      " [-1.0072]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.0115]\n",
      " [ 0.2558]\n",
      " [-1.0072]]\n",
      "d_bias2 = f[-1.7629]\n",
      "  2*(self.y - self.output) = f[[-1.0115]\n",
      " [ 0.2558]\n",
      " [-1.0072]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.0115]\n",
      " [ 0.2558]\n",
      " [-1.0072]]\n",
      "\n",
      "Testing epoch #8\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.8802]\n",
      " [-1.8802]]\n",
      "Bias2: [-0.4009]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #9\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.2113034890615204\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.563 ]\n",
      " [1.007 ]\n",
      " [0.5629]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.4802]\n",
      " [-1.4802]]\n",
      "Bias2: [1.5991]\n",
      "d_weights2 = f[[-0.7909]\n",
      " [-0.791 ]]\n",
      "  2*(self.y - self.output) = f[[-1.126 ]\n",
      " [-0.0141]\n",
      " [-1.1259]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.126 ]\n",
      " [-0.0141]\n",
      " [-1.1259]]\n",
      "d_bias2 = f[-2.2659]\n",
      "  2*(self.y - self.output) = f[[-1.126 ]\n",
      " [-0.0141]\n",
      " [-1.1259]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.126 ]\n",
      " [-0.0141]\n",
      " [-1.1259]]\n",
      "\n",
      "Testing epoch #10\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.2712]\n",
      " [-2.2712]]\n",
      "Bias2: [-0.6668]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #11\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.05784866089018767\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.0234]\n",
      " [0.5847]\n",
      " [0.0234]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.8712]\n",
      " [-1.8712]]\n",
      "Bias2: [1.3332]\n",
      "d_weights2 = f[[0.1334]\n",
      " [0.1334]]\n",
      "  2*(self.y - self.output) = f[[-0.0468]\n",
      " [ 0.8305]\n",
      " [-0.0468]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-0.0468]\n",
      " [ 0.8305]\n",
      " [-0.0468]]\n",
      "d_bias2 = f[0.737]\n",
      "  2*(self.y - self.output) = f[[-0.0468]\n",
      " [ 0.8305]\n",
      " [-0.0468]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-0.0468]\n",
      " [ 0.8305]\n",
      " [-0.0468]]\n",
      "\n",
      "Testing epoch #12\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.5328771642042851\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.8538]\n",
      " [1.3751]\n",
      " [0.8538]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-1.7378]\n",
      " [-1.7378]]\n",
      "Bias2: [2.0702]\n",
      "d_weights2 = f[[-1.3454]\n",
      " [-1.3454]]\n",
      "  2*(self.y - self.output) = f[[-1.7076]\n",
      " [-0.7502]\n",
      " [-1.7076]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.7076]\n",
      " [-0.7502]\n",
      " [-1.7076]]\n",
      "d_bias2 = f[-4.1654]\n",
      "  2*(self.y - self.output) = f[[-1.7076]\n",
      " [-0.7502]\n",
      " [-1.7076]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.7076]\n",
      " [-0.7502]\n",
      " [-1.7076]]\n",
      "\n",
      "Testing epoch #13\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.0831]\n",
      " [-3.0831]]\n",
      "Bias2: [-2.0952]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #14\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.6831]\n",
      " [-2.6831]]\n",
      "Bias2: [-0.0952]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #15\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.06270690242688928\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.3066]\n",
      " [0.9916]\n",
      " [0.3066]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.2831]\n",
      " [-2.2831]]\n",
      "Bias2: [1.9048]\n",
      "d_weights2 = f[[-0.4259]\n",
      " [-0.4259]]\n",
      "  2*(self.y - self.output) = f[[-0.6133]\n",
      " [ 0.0168]\n",
      " [-0.6133]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-0.6133]\n",
      " [ 0.0168]\n",
      " [-0.6133]]\n",
      "d_bias2 = f[-1.2097]\n",
      "  2*(self.y - self.output) = f[[-0.6133]\n",
      " [ 0.0168]\n",
      " [-0.6133]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-0.6133]\n",
      " [ 0.0168]\n",
      " [-0.6133]]\n",
      "\n",
      "Testing epoch #16\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.7091]\n",
      " [-2.7091]]\n",
      "Bias2: [0.6951]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #17\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.9742887333688431\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[1.0788]\n",
      " [1.7715]\n",
      " [1.0788]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.3091]\n",
      " [-2.3091]]\n",
      "Bias2: [2.6951]\n",
      "d_weights2 = f[[-1.8189]\n",
      " [-1.8189]]\n",
      "  2*(self.y - self.output) = f[[-2.1576]\n",
      " [-1.543 ]\n",
      " [-2.1576]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-2.1576]\n",
      " [-1.543 ]\n",
      " [-2.1576]]\n",
      "d_bias2 = f[-5.8582]\n",
      "  2*(self.y - self.output) = f[[-2.1576]\n",
      " [-1.543 ]\n",
      " [-2.1576]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-2.1576]\n",
      " [-1.543 ]\n",
      " [-2.1576]]\n",
      "\n",
      "Testing epoch #18\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-4.128]\n",
      " [-4.128]]\n",
      "Bias2: [-3.1631]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #19\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.728]\n",
      " [-3.728]]\n",
      "Bias2: [-1.1631]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #20\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.328]\n",
      " [-3.328]]\n",
      "Bias2: [0.8369]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #21\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.5609564868930114\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.7873]\n",
      " [1.6657]\n",
      " [0.7873]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-2.928]\n",
      " [-2.928]]\n",
      "Bias2: [2.8369]\n",
      "d_weights2 = f[[-1.3685]\n",
      " [-1.3685]]\n",
      "  2*(self.y - self.output) = f[[-1.5746]\n",
      " [-1.3314]\n",
      " [-1.5746]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.5746]\n",
      " [-1.3314]\n",
      " [-1.5746]]\n",
      "d_bias2 = f[-4.4806]\n",
      "  2*(self.y - self.output) = f[[-1.5746]\n",
      " [-1.3314]\n",
      " [-1.5746]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[-1.5746]\n",
      " [-1.3314]\n",
      " [-1.5746]]\n",
      "\n",
      "Testing epoch #22\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-4.2965]\n",
      " [-4.2965]]\n",
      "Bias2: [-1.6437]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #23\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.3333333333333333\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.8965]\n",
      " [-3.8965]]\n",
      "Bias2: [0.3563]\n",
      "d_weights2 = f[[0.4]\n",
      " [0.4]]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "d_bias2 = f[2.]\n",
      "  2*(self.y - self.output) = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "  d_activation(self.output) = f[[1]\n",
      " [1]\n",
      " [1]]\n",
      "  z = f[[0.]\n",
      " [2.]\n",
      " [0.]]\n",
      "\n",
      "Testing epoch #24\n",
      "\n",
      "Neural network with 1 hidden layer of size 2\n",
      "Current loss: 0.0005975973202192865\n",
      "Inputs: [[0. ]\n",
      " [0.5]\n",
      " [1. ]]\n",
      "Layer: [[0.  0.7]\n",
      " [0.2 0.2]\n",
      " [0.7 0. ]]\n",
      "Outputs: [[0.    ]\n",
      " [0.9577]\n",
      " [0.    ]]\n",
      "Weights1: [[ 1 -1]]\n",
      "Bias1: [[-0.3  0.7]]\n",
      "Weights2: [[-3.4965]\n",
      " [-3.4965]]\n",
      "Bias2: [2.3563]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "activation = relu\n",
    "d_activation = relu_derivative\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=200)\n",
    "\n",
    "class NeuralNet:\n",
    "    # What is the type of x and y???\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.input = self.x\n",
    "        # self.weights1 = np.random.rand(x.shape[1], 2) - 0.5\n",
    "        # self.bias1 = np.zeros(2)\n",
    "        self.weights2 = np.random.rand(2, 1) - 0.5\n",
    "        self.bias2 = np.zeros(1)\n",
    "        self.weights1 = np.array([[1, -1]])\n",
    "        self.bias1 = np.array([[-0.3, 0.7]])\n",
    "        #self.weights2 = np.array([[-3.1], [-3.2]])\n",
    "        #self.bias2 = np.array([[2.2]])\n",
    "        self.output = np.zeros(self.y.shape)\n",
    "        self.learning_rate = 1\n",
    "\n",
    "    def feedforward(self):\n",
    "        # print(f\"layer1 z = {np.dot(self.input, self.weights1) + self.bias1}\")\n",
    "        layer1 = activation(np.dot(self.input, self.weights1) + self.bias1)\n",
    "        self.layer1 = layer1\n",
    "        # print(f\"layer1 = {self.layer1}\")\n",
    "        # print(f\"output z = {np.dot(self.layer1, self.weights2) + self.bias2}\")\n",
    "        output = activation(np.dot(layer1, self.weights2) + self.bias2)\n",
    "        self.output = output\n",
    "        # print(f\"output = {self.output}\")\n",
    "\n",
    "    def backpropagate(self):\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * d_activation(self.output)))\n",
    "        print(f\"d_weights2 = f{d_weights2}\")\n",
    "        print(f\"  2*(self.y - self.output) = f{2*(self.y - self.output)}\")\n",
    "        print(f\"  d_activation(self.output) = f{d_activation(self.output)}\")\n",
    "        print(f\"  z = f{2*(self.y - self.output) * d_activation(self.output)}\")\n",
    "        d_bias2 = np.sum(2*(self.y - self.output) * d_activation(self.output), axis=0)\n",
    "        print(f\"d_bias2 = f{d_bias2}\")\n",
    "        print(f\"  2*(self.y - self.output) = f{2*(self.y - self.output)}\")\n",
    "        print(f\"  d_activation(self.output) = f{d_activation(self.output)}\")\n",
    "        print(f\"  z = f{2*(self.y - self.output) * d_activation(self.output)}\")\n",
    "        # print(f\"d_bias2 = {d_bias2}\")\n",
    "        # print(f\"bias2 = {self.bias2}\")\n",
    "        #d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * d_activation(self.output), self.weights2.T) * d_activation(self.layer1)))\n",
    "        #d_bias1 = (np.dot(2*(self.y - self.output) * d_activation(self.output), self.weights2.T) * d_activation(self.layer1))\n",
    "        #print(f\"d_bias1 = {d_bias1}\")\n",
    "        #self.weights1 += d_weights1 * self.learning_rate\n",
    "        #self.bias1 += d_bias1 * self.learning_rate\n",
    "        self.weights2 += d_weights2 * self.learning_rate\n",
    "        self.bias2 += d_bias2 * self.learning_rate\n",
    "\n",
    "    def display(self):\n",
    "        print()\n",
    "        print(\"Neural network with 1 hidden layer of size 2\")\n",
    "        print(f\"Current loss: {self.loss()}\")\n",
    "        print(f\"Inputs: {self.input}\")\n",
    "        print(f\"Layer: {self.layer1}\")\n",
    "        print(f\"Outputs: {self.output}\")\n",
    "        print(f\"Weights1: {self.weights1}\")\n",
    "        print(f\"Bias1: {self.bias1}\")\n",
    "        print(f\"Weights2: {self.weights2}\")\n",
    "        print(f\"Bias2: {self.bias2}\")\n",
    "\n",
    "    def test(self, inputs):\n",
    "        #print(f\"layer1 z = {np.dot(inputs, self.weights1) + self.bias1}\")\n",
    "        layer1 = activation(np.dot(inputs, self.weights1) + self.bias1)\n",
    "        #print(f\"layer1 = {self.layer1}\")\n",
    "        #print(f\"output z = {np.dot(self.layer1, self.weights2) + self.bias2}\")\n",
    "        output = activation(np.dot(layer1, self.weights2) + self.bias2)\n",
    "        #print(f\"output = {self.output}\")\n",
    "        return output\n",
    "\n",
    "    def loss(self):\n",
    "        return np.average((self.y - self.output) ** 2)\n",
    "\n",
    "    def mean_of_square_errors(predicted, actual):\n",
    "        if len(predicted) != len(actual):\n",
    "            sys.exit(\"mean_of_square_errors: Predict and actual are different length\")\n",
    "        sum = 0\n",
    "        for i in range(len(predicted)):\n",
    "            sum += (predicted[i] - actual[i]) ** 2\n",
    "        return sum / len(predicted)\n",
    "\n",
    "# Add function to plot shape of x vs y\n",
    "def plot(nn):\n",
    "    x = np.linspace(0, 1)\n",
    "    y = nn.test(np.array(x)[np.newaxis].T)\n",
    "    plt.plot(x,y)\n",
    "\n",
    "x = np.array([ [0], [0.5], [1] ])\n",
    "y = np.array([ [0], [1], [0] ])\n",
    "\n",
    "nn = NeuralNet(x,y)\n",
    "\n",
    "nn.feedforward()\n",
    "nn.display()\n",
    "for i in range(100):\n",
    "    nn.backpropagate()\n",
    "    nn.feedforward()\n",
    "    print(f\"\\nTesting epoch #{i+1}\")\n",
    "    nn.display()\n",
    "    if nn.loss() < 0.01:\n",
    "        break\n",
    "\n",
    "plot(nn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
